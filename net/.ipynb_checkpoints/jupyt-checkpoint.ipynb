{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorwatch as tw\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchviz import make_dot\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "nclasses = 62 # GTSRB as 43 classes\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(250)\n",
    "        self.conv_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(2250, 350)\n",
    "        self.fc2 = nn.Linear(350, nclasses)\n",
    "        self.filters = 250\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        # 子网络（全连接或卷积网络，再加上一个回归层）用来生成空间变换的参数θ，θ的形式可以多样，\n",
    "        # 如需实现2D仿射变换，θ 就是一个6维（2x3）向量的输出\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 7 * 7, 32),                # 160*32\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)                      # 32*6\n",
    "            )\n",
    "   \n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "        # SENet\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Conv2d(self.filters, self.filters//16, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.filters//16, self.filters, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    # 整个空间变换器包含三个部分，本地网络(Localisation Network)、网格生成器(Grid Genator)和采样器(Sampler)\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)         # torch.Size([1, 10, 4, 4])\n",
    "        xs = xs.view(-1, 10 * 7 * 7)               # 361, 160\n",
    "        print(xs.size())\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        print(theta.size())\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform forward pass\n",
    "        x = self.bn1(F.max_pool2d(F.leaky_relu(self.conv1(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn2(F.max_pool2d(F.leaky_relu(self.conv2(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn3(F.max_pool2d(F.leaky_relu(self.conv3(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x1 = self.se(x)\n",
    "        x = x * x1\n",
    "        x = x.view(-1, 2250)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        # out = avg_out + max_out\n",
    "        # return self.sigmoid(out)\n",
    "        return avg_out, max_out\n",
    "\n",
    "# ======================= spatial ==============================\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)   # 输出与输入有相同的维度\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "nclasses = 43  # GTSRB as 43 classes\n",
    "\n",
    "def mish_fun(x):\n",
    "    return x * (torch.tanh(F.softplus(x)))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # print(\"Mish activation loaded...\")\n",
    "    def forward(self,x):\n",
    "        x = x * (torch.tanh(F.softplus(x)))\n",
    "        return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(250)\n",
    "        self.conv4 = nn.Conv2d(250, 250, kernel_size=2)\n",
    "        self.bn4 = nn.BatchNorm2d(250)\n",
    "        self.conv_c = nn.Conv2d(500, 250, kernel_size=3, padding=2)\n",
    "        self.bn_c = nn.BatchNorm2d(250)\n",
    "\n",
    "        self.conv_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(250, nclasses)\n",
    "        self.filters = 250\n",
    "        self.glob = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        #  attention\n",
    "        self.ca = ChannelAttention(self.filters)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            # nn.ReLU(True),\n",
    "            Mish(),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            # nn.ReLU(True)\n",
    "            Mish()\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        # 子网络（全连接或卷积网络，再加上一个回归层）用来生成空间变换的参数θ，θ的形式可以多样，\n",
    "        # 如需实现2D仿射变换，θ 就是一个6维（2x3）向量的输出\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 7 * 7, 32),  # 160*32\n",
    "            # nn.ReLU(True),\n",
    "            Mish(),\n",
    "            nn.Linear(32, 3 * 2)  # 32*6\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    # 整个空间变换器包含三个部分，本地网络(Localisation Network)、网格生成器(Grid Genator)和采样器(Sampler)\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)  # torch.Size([1, 10, 4, 4])\n",
    "        xs = xs.view(-1, 10 * 7 * 7)  # 361, 160\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform forward pass\n",
    "        x = self.bn1(F.max_pool2d(mish_fun(self.conv1(x)), 2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn2(F.max_pool2d(mish_fun(self.conv2(x)), 2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn3(F.max_pool2d(mish_fun(self.conv3(x)), 2))\n",
    "        x = self.conv_drop(x)\n",
    "        #  channel\n",
    "        avg_pool, max_pool = self.ca(x)\n",
    "        avg_pool_out = x * avg_pool\n",
    "        max_pool_out = x * max_pool\n",
    "        # concate\n",
    "        x = torch.cat((avg_pool_out, max_pool_out), -1, x)\n",
    "        x = self.bn_c(F.max_pool2d(mish_fun(self.conv_c(x)), 2))\n",
    "        x = self.conv_drop(x)\n",
    "\n",
    "        x = self.bn4(self.glob(mish_fun(self.conv4(x))))\n",
    "        x = self.conv_drop(x)\n",
    "        x1 = self.sa(x)\n",
    "        x = x * x1\n",
    "        x = x.view(-1, 250)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAdd]: Mish is not supported!\n",
      "[Flops]: Mish is not supported!\n",
      "[Memory]: Mish is not supported!\n",
      "[MAdd]: Mish is not supported!\n",
      "[Flops]: Mish is not supported!\n",
      "[Memory]: Mish is not supported!\n",
      "[MAdd]: Mish is not supported!\n",
      "[Flops]: Mish is not supported!\n",
      "[Memory]: Mish is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveMaxPool2d is not supported!\n",
      "[Flops]: AdaptiveMaxPool2d is not supported!\n",
      "[Memory]: AdaptiveMaxPool2d is not supported!\n",
      "[MAdd]: AdaptiveMaxPool2d is not supported!\n",
      "[Flops]: AdaptiveMaxPool2d is not supported!\n",
      "[Memory]: AdaptiveMaxPool2d is not supported!\n",
      "[MAdd]: AdaptiveMaxPool2d is not supported!\n",
      "[Flops]: AdaptiveMaxPool2d is not supported!\n",
      "[Memory]: AdaptiveMaxPool2d is not supported!\n",
      "[MAdd]: AdaptiveMaxPool2d is not supported!\n",
      "[Flops]: AdaptiveMaxPool2d is not supported!\n",
      "[Memory]: AdaptiveMaxPool2d is not supported!\n",
      "[MAdd]: AdaptiveMaxPool2d is not supported!\n",
      "[Flops]: AdaptiveMaxPool2d is not supported!\n",
      "[Memory]: AdaptiveMaxPool2d is not supported!\n",
      "[MAdd]: AdaptiveMaxPool2d is not supported!\n",
      "[Flops]: AdaptiveMaxPool2d is not supported!\n",
      "[Memory]: AdaptiveMaxPool2d is not supported!\n",
      "[MAdd]: AdaptiveMaxPool2d is not supported!\n",
      "[Flops]: AdaptiveMaxPool2d is not supported!\n",
      "[Memory]: AdaptiveMaxPool2d is not supported!\n",
      "[MAdd]: AdaptiveMaxPool2d is not supported!\n",
      "[Flops]: AdaptiveMaxPool2d is not supported!\n",
      "[Memory]: AdaptiveMaxPool2d is not supported!\n",
      "torch.Size([1, 500, 3, 3])\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Sigmoid is not supported!\n",
      "[Flops]: Sigmoid is not supported!\n",
      "[Memory]: Sigmoid is not supported!\n",
      "[MAdd]: Sigmoid is not supported!\n",
      "[Flops]: Sigmoid is not supported!\n",
      "[Memory]: Sigmoid is not supported!\n",
      "[MAdd]: Sigmoid is not supported!\n",
      "[Flops]: Sigmoid is not supported!\n",
      "[Memory]: Sigmoid is not supported!\n",
      "[MAdd]: Sigmoid is not supported!\n",
      "[Flops]: Sigmoid is not supported!\n",
      "[Memory]: Sigmoid is not supported!\n",
      "[MAdd]: Sigmoid is not supported!\n",
      "[Flops]: Sigmoid is not supported!\n",
      "[Memory]: Sigmoid is not supported!\n",
      "[MAdd]: Sigmoid is not supported!\n",
      "[Flops]: Sigmoid is not supported!\n",
      "[Memory]: Sigmoid is not supported!\n",
      "[MAdd]: Sigmoid is not supported!\n",
      "[Flops]: Sigmoid is not supported!\n",
      "[Memory]: Sigmoid is not supported!\n",
      "[MAdd]: Sigmoid is not supported!\n",
      "[Flops]: Sigmoid is not supported!\n",
      "[Memory]: Sigmoid is not supported!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>module name</th>\n",
       "      <th>input shape</th>\n",
       "      <th>output shape</th>\n",
       "      <th>params</th>\n",
       "      <th>memory(MB)</th>\n",
       "      <th>MAdd</th>\n",
       "      <th>Flops</th>\n",
       "      <th>MemRead(B)</th>\n",
       "      <th>MemWrite(B)</th>\n",
       "      <th>duration[%]</th>\n",
       "      <th>MemR+W(B)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>conv1</td>\n",
       "      <td>3  43  43</td>\n",
       "      <td>100  41  41</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9,077,400.0</td>\n",
       "      <td>4,706,800.0</td>\n",
       "      <td>33388.0</td>\n",
       "      <td>672400.0</td>\n",
       "      <td>2.01%</td>\n",
       "      <td>705788.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bn1</td>\n",
       "      <td>100  20  20</td>\n",
       "      <td>100  20  20</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>160,000.0</td>\n",
       "      <td>80,000.0</td>\n",
       "      <td>160800.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>1.72%</td>\n",
       "      <td>320800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>conv2</td>\n",
       "      <td>100  20  20</td>\n",
       "      <td>150  18  18</td>\n",
       "      <td>135150.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>87,480,000.0</td>\n",
       "      <td>43,788,600.0</td>\n",
       "      <td>700600.0</td>\n",
       "      <td>194400.0</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>895000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bn2</td>\n",
       "      <td>150   9   9</td>\n",
       "      <td>150   9   9</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>48,600.0</td>\n",
       "      <td>24,300.0</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>48600.0</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>98400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>conv3</td>\n",
       "      <td>150   9   9</td>\n",
       "      <td>250   7   7</td>\n",
       "      <td>337750.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>33,075,000.0</td>\n",
       "      <td>16,549,750.0</td>\n",
       "      <td>1399600.0</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>3.43%</td>\n",
       "      <td>1448600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>bn3</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,000.0</td>\n",
       "      <td>4,500.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>1.60%</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>conv4</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>250   2   2</td>\n",
       "      <td>250250.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2,000,000.0</td>\n",
       "      <td>1,001,000.0</td>\n",
       "      <td>1010000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>3.83%</td>\n",
       "      <td>1014000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>bn4</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.29%</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>conv_c</td>\n",
       "      <td>500   3   3</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>1125250.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20,250,000.0</td>\n",
       "      <td>10,127,250.0</td>\n",
       "      <td>4519000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>4528000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>bn_c</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,000.0</td>\n",
       "      <td>4,500.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>1.73%</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>conv_drop</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.12%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>fc1</td>\n",
       "      <td>250</td>\n",
       "      <td>43</td>\n",
       "      <td>10793.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21,457.0</td>\n",
       "      <td>10,750.0</td>\n",
       "      <td>44172.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.47%</td>\n",
       "      <td>44344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>glob</td>\n",
       "      <td>250   2   2</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.86%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>ca.avg_pool</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.46%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>ca.max_pool</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.30%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>ca.fc1</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>15   1   1</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7,485.0</td>\n",
       "      <td>3,750.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.14%</td>\n",
       "      <td>16060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>ca.relu1</td>\n",
       "      <td>15   1   1</td>\n",
       "      <td>15   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.39%</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>ca.fc2</td>\n",
       "      <td>15   1   1</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7,250.0</td>\n",
       "      <td>3,750.0</td>\n",
       "      <td>15060.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.00%</td>\n",
       "      <td>16060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>ca.sigmoid</td>\n",
       "      <td>0   0   0</td>\n",
       "      <td>0   0   0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>sa.conv1</td>\n",
       "      <td>2   1   1</td>\n",
       "      <td>1   1   1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>195.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.58%</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>sa.sigmoid</td>\n",
       "      <td>1   1   1</td>\n",
       "      <td>1   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.64%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>localization.0</td>\n",
       "      <td>3  43  43</td>\n",
       "      <td>8  37  37</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3,219,888.0</td>\n",
       "      <td>1,620,896.0</td>\n",
       "      <td>26924.0</td>\n",
       "      <td>43808.0</td>\n",
       "      <td>8.51%</td>\n",
       "      <td>70732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>localization.1</td>\n",
       "      <td>8  37  37</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7,776.0</td>\n",
       "      <td>10,952.0</td>\n",
       "      <td>43808.0</td>\n",
       "      <td>10368.0</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>54176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>localization.2</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>localization.3</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>10  14  14</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>784,000.0</td>\n",
       "      <td>393,960.0</td>\n",
       "      <td>18408.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>3.24%</td>\n",
       "      <td>26248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>localization.4</td>\n",
       "      <td>10  14  14</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,470.0</td>\n",
       "      <td>1,960.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>2.66%</td>\n",
       "      <td>9800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>localization.5</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>fc_loc.0</td>\n",
       "      <td>490</td>\n",
       "      <td>32</td>\n",
       "      <td>15712.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31,328.0</td>\n",
       "      <td>15,680.0</td>\n",
       "      <td>64808.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.16%</td>\n",
       "      <td>64936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>fc_loc.1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>fc_loc.2</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>378.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.00%</td>\n",
       "      <td>944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1890695.0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>156,191,242.0</td>\n",
       "      <td>78,349,203.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>9358412.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          module name  input shape output shape     params memory(MB)           MAdd         Flops  MemRead(B)  MemWrite(B) duration[%]  MemR+W(B)\n",
       "0               conv1    3  43  43  100  41  41     2800.0       0.64    9,077,400.0   4,706,800.0     33388.0     672400.0       2.01%   705788.0\n",
       "1                 bn1  100  20  20  100  20  20      200.0       0.15      160,000.0      80,000.0    160800.0     160000.0       1.72%   320800.0\n",
       "2               conv2  100  20  20  150  18  18   135150.0       0.19   87,480,000.0  43,788,600.0    700600.0     194400.0       3.87%   895000.0\n",
       "3                 bn2  150   9   9  150   9   9      300.0       0.05       48,600.0      24,300.0     49800.0      48600.0       1.61%    98400.0\n",
       "4               conv3  150   9   9  250   7   7   337750.0       0.05   33,075,000.0  16,549,750.0   1399600.0      49000.0       3.43%  1448600.0\n",
       "5                 bn3  250   3   3  250   3   3      500.0       0.01        9,000.0       4,500.0     11000.0       9000.0       1.60%    20000.0\n",
       "6               conv4  250   3   3  250   2   2   250250.0       0.00    2,000,000.0   1,001,000.0   1010000.0       4000.0       3.83%  1014000.0\n",
       "7                 bn4  250   1   1  250   1   1      500.0       0.00        1,000.0         500.0      3000.0       1000.0       3.29%     4000.0\n",
       "8              conv_c  500   3   3  250   3   3  1125250.0       0.01   20,250,000.0  10,127,250.0   4519000.0       9000.0       4.10%  4528000.0\n",
       "9                bn_c  250   3   3  250   3   3      500.0       0.01        9,000.0       4,500.0     11000.0       9000.0       1.73%    20000.0\n",
       "10          conv_drop  250   1   1  250   1   1        0.0       0.00            0.0           0.0         0.0          0.0       3.12%        0.0\n",
       "11                fc1          250           43    10793.0       0.00       21,457.0      10,750.0     44172.0        172.0       1.47%    44344.0\n",
       "12               glob  250   2   2  250   1   1        0.0       0.00            0.0           0.0         0.0          0.0       4.86%        0.0\n",
       "13        ca.avg_pool  250   3   3  250   1   1        0.0       0.00            0.0           0.0         0.0          0.0       6.46%        0.0\n",
       "14        ca.max_pool  250   3   3  250   1   1        0.0       0.00            0.0           0.0         0.0          0.0       2.30%        0.0\n",
       "15             ca.fc1  250   1   1   15   1   1     3750.0       0.00        7,485.0       3,750.0     16000.0         60.0       2.14%    16060.0\n",
       "16           ca.relu1   15   1   1   15   1   1        0.0       0.00           15.0          15.0        60.0         60.0       1.39%      120.0\n",
       "17             ca.fc2   15   1   1  250   1   1     3750.0       0.00        7,250.0       3,750.0     15060.0       1000.0       2.00%    16060.0\n",
       "18         ca.sigmoid    0   0   0    0   0   0        0.0       0.00            0.0           0.0         0.0          0.0       0.00%        0.0\n",
       "19           sa.conv1    2   1   1    1   1   1       98.0       0.00          195.0          98.0       400.0          4.0      22.58%      404.0\n",
       "20         sa.sigmoid    1   1   1    1   1   1        0.0       0.00            0.0           0.0         0.0          0.0       3.64%        0.0\n",
       "21     localization.0    3  43  43    8  37  37     1184.0       0.04    3,219,888.0   1,620,896.0     26924.0      43808.0       8.51%    70732.0\n",
       "22     localization.1    8  37  37    8  18  18        0.0       0.01        7,776.0      10,952.0     43808.0      10368.0       2.77%    54176.0\n",
       "23     localization.2    8  18  18    8  18  18        0.0       0.01            0.0           0.0         0.0          0.0       0.30%        0.0\n",
       "24     localization.3    8  18  18   10  14  14     2010.0       0.01      784,000.0     393,960.0     18408.0       7840.0       3.24%    26248.0\n",
       "25     localization.4   10  14  14   10   7   7        0.0       0.00        1,470.0       1,960.0      7840.0       1960.0       2.66%     9800.0\n",
       "26     localization.5   10   7   7   10   7   7        0.0       0.00            0.0           0.0         0.0          0.0       0.13%        0.0\n",
       "27           fc_loc.0          490           32    15712.0       0.00       31,328.0      15,680.0     64808.0        128.0       3.16%    64936.0\n",
       "28           fc_loc.1           32           32        0.0       0.00            0.0           0.0         0.0          0.0       0.07%        0.0\n",
       "29           fc_loc.2           32            6      198.0       0.00          378.0         192.0       920.0         24.0       2.00%      944.0\n",
       "total                                            1890695.0       1.18  156,191,242.0  78,349,203.0       920.0         24.0     100.00%  9358412.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        # out = avg_out + max_out\n",
    "        # return self.sigmoid(out)\n",
    "        return avg_out, max_out\n",
    "\n",
    "# ======================= spatial ==============================\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)   # 输出与输入有相同的维度\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "nclasses = 43  # GTSRB as 43 classes\n",
    "\n",
    "def mish_fun(x):\n",
    "    return x * (torch.tanh(F.softplus(x)))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # print(\"Mish activation loaded...\")\n",
    "    def forward(self,x):\n",
    "        x = x * (torch.tanh(F.softplus(x)))\n",
    "        return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(250)\n",
    "        self.conv4 = nn.Conv2d(250, 250, kernel_size=2)\n",
    "        self.bn4 = nn.BatchNorm2d(250)\n",
    "        self.conv_c = nn.Conv2d(500, 250, kernel_size=3, padding=1)\n",
    "        self.conv_1 = nn.Conv2d(500, 250, kernel_size=1)\n",
    "        self.bn_c = nn.BatchNorm2d(250)\n",
    "\n",
    "        self.conv_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(250, nclasses)\n",
    "        self.filters = 250\n",
    "        self.glob = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        #  attention\n",
    "        self.ca = ChannelAttention(self.filters)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            # nn.ReLU(True),\n",
    "            Mish(),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            # nn.ReLU(True)\n",
    "            Mish()\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        # 子网络（全连接或卷积网络，再加上一个回归层）用来生成空间变换的参数θ，θ的形式可以多样，\n",
    "        # 如需实现2D仿射变换，θ 就是一个6维（2x3）向量的输出\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 7 * 7, 32),  # 160*32\n",
    "            # nn.ReLU(True),\n",
    "            Mish(),\n",
    "            nn.Linear(32, 3 * 2)  # 32*6\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    # 整个空间变换器包含三个部分，本地网络(Localisation Network)、网格生成器(Grid Genator)和采样器(Sampler)\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)  # torch.Size([1, 10, 4, 4])\n",
    "        xs = xs.view(-1, 10 * 7 * 7)  # 361, 160\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform forward pass\n",
    "        x = self.bn1(F.max_pool2d(mish_fun(self.conv1(x)), 2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn2(F.max_pool2d(mish_fun(self.conv2(x)), 2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn3(F.max_pool2d(mish_fun(self.conv3(x)), 2))\n",
    "        x = self.conv_drop(x)\n",
    "        #  channel\n",
    "        avg_pool, max_pool = self.ca(x)\n",
    "        avg_pool_out = x * avg_pool\n",
    "        max_pool_out = x * max_pool\n",
    "        # concate\n",
    "        x1 = torch.cat((avg_pool_out, max_pool_out), 1)\n",
    "        print(x1.shape)\n",
    "        \n",
    "#         x = self.bn_c(mish_fun(self.conv_c(x1)))\n",
    "        x = self.bn_c(mish_fun(self.conv_1(x1)))\n",
    "        x = self.conv_drop(x)\n",
    "\n",
    "        x = self.bn4(self.glob(mish_fun(self.conv4(x))))\n",
    "        x = self.conv_drop(x)\n",
    "        x1 = self.sa(x)\n",
    "        x = x * x1\n",
    "        x = x.view(-1, 250)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "import tensorwatch as tw\n",
    "tw.model_stats(model, [16, 3, 43, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>module name</th>\n",
       "      <th>input shape</th>\n",
       "      <th>output shape</th>\n",
       "      <th>params</th>\n",
       "      <th>memory(MB)</th>\n",
       "      <th>MAdd</th>\n",
       "      <th>Flops</th>\n",
       "      <th>MemRead(B)</th>\n",
       "      <th>MemWrite(B)</th>\n",
       "      <th>duration[%]</th>\n",
       "      <th>MemR+W(B)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3  43  43</td>\n",
       "      <td>8  37  37</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3,219,888.0</td>\n",
       "      <td>1,620,896.0</td>\n",
       "      <td>26924.0</td>\n",
       "      <td>43808.0</td>\n",
       "      <td>21.62%</td>\n",
       "      <td>70732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8  37  37</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7,776.0</td>\n",
       "      <td>10,952.0</td>\n",
       "      <td>43808.0</td>\n",
       "      <td>10368.0</td>\n",
       "      <td>22.42%</td>\n",
       "      <td>54176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,592.0</td>\n",
       "      <td>2,592.0</td>\n",
       "      <td>10368.0</td>\n",
       "      <td>10368.0</td>\n",
       "      <td>8.76%</td>\n",
       "      <td>20736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>10  14  14</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>784,000.0</td>\n",
       "      <td>393,960.0</td>\n",
       "      <td>18408.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>15.31%</td>\n",
       "      <td>26248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10  14  14</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,470.0</td>\n",
       "      <td>1,960.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>18.03%</td>\n",
       "      <td>9800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>490.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>13.85%</td>\n",
       "      <td>3920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3194.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>4,016,216.0</td>\n",
       "      <td>2,030,850.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>185612.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      module name  input shape output shape  params memory(MB)         MAdd        Flops  MemRead(B)  MemWrite(B) duration[%]  MemR+W(B)\n",
       "0               0    3  43  43    8  37  37  1184.0       0.04  3,219,888.0  1,620,896.0     26924.0      43808.0      21.62%    70732.0\n",
       "1               1    8  37  37    8  18  18     0.0       0.01      7,776.0     10,952.0     43808.0      10368.0      22.42%    54176.0\n",
       "2               2    8  18  18    8  18  18     0.0       0.01      2,592.0      2,592.0     10368.0      10368.0       8.76%    20736.0\n",
       "3               3    8  18  18   10  14  14  2010.0       0.01    784,000.0    393,960.0     18408.0       7840.0      15.31%    26248.0\n",
       "4               4   10  14  14   10   7   7     0.0       0.00      1,470.0      1,960.0      7840.0       1960.0      18.03%     9800.0\n",
       "5               5   10   7   7   10   7   7     0.0       0.00        490.0        490.0      1960.0       1960.0      13.85%     3920.0\n",
       "total                                        3194.0       0.07  4,016,216.0  2,030,850.0      1960.0       1960.0     100.00%   185612.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "tw.model_stats(localization, [16, 3, 43, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>module name</th>\n",
       "      <th>input shape</th>\n",
       "      <th>output shape</th>\n",
       "      <th>params</th>\n",
       "      <th>memory(MB)</th>\n",
       "      <th>MAdd</th>\n",
       "      <th>Flops</th>\n",
       "      <th>MemRead(B)</th>\n",
       "      <th>MemWrite(B)</th>\n",
       "      <th>duration[%]</th>\n",
       "      <th>MemR+W(B)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>_features.0</td>\n",
       "      <td>3  43  43</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>9408.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>9,075,968.0</td>\n",
       "      <td>4,553,472.0</td>\n",
       "      <td>59820.0</td>\n",
       "      <td>123904.0</td>\n",
       "      <td>1.98%</td>\n",
       "      <td>183724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>_features.1</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>123,904.0</td>\n",
       "      <td>61,952.0</td>\n",
       "      <td>124416.0</td>\n",
       "      <td>123904.0</td>\n",
       "      <td>1.47%</td>\n",
       "      <td>248320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>_features.2</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>123904.0</td>\n",
       "      <td>123904.0</td>\n",
       "      <td>1.26%</td>\n",
       "      <td>247808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>_features.3</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>61,952.0</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>123904.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.96%</td>\n",
       "      <td>154880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>_features.4.0.conv1</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8,913,344.0</td>\n",
       "      <td>4,460,544.0</td>\n",
       "      <td>178432.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.75%</td>\n",
       "      <td>209408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>_features.4.0.bn1</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>15,488.0</td>\n",
       "      <td>31488.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>0.86%</td>\n",
       "      <td>62464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>_features.4.0.relu</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7,744.0</td>\n",
       "      <td>7,744.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.17%</td>\n",
       "      <td>61952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>_features.4.0.conv2</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8,913,344.0</td>\n",
       "      <td>4,460,544.0</td>\n",
       "      <td>178432.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.91%</td>\n",
       "      <td>209408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>_features.4.0.bn2</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>15,488.0</td>\n",
       "      <td>31488.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>62464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>_features.4.1.conv1</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8,913,344.0</td>\n",
       "      <td>4,460,544.0</td>\n",
       "      <td>178432.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.76%</td>\n",
       "      <td>209408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>_features.4.1.bn1</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>15,488.0</td>\n",
       "      <td>31488.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>62464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>_features.4.1.relu</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7,744.0</td>\n",
       "      <td>7,744.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>61952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>_features.4.1.conv2</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8,913,344.0</td>\n",
       "      <td>4,460,544.0</td>\n",
       "      <td>178432.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.78%</td>\n",
       "      <td>209408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>_features.4.1.bn2</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>15,488.0</td>\n",
       "      <td>31488.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>62464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>_features.5.0.conv1</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>73728.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5,303,808.0</td>\n",
       "      <td>2,654,208.0</td>\n",
       "      <td>325888.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>344320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>_features.5.0.bn1</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>18,432.0</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>19456.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>37888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>_features.5.0.relu</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>36864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>_features.5.0.conv2</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>147456.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10,612,224.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>608256.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>1.93%</td>\n",
       "      <td>626688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>_features.5.0.bn2</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>18,432.0</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>19456.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.84%</td>\n",
       "      <td>37888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>_features.5.0.downsample.0</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>585,216.0</td>\n",
       "      <td>294,912.0</td>\n",
       "      <td>63744.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>1.58%</td>\n",
       "      <td>82176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>_features.5.0.downsample.1</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>18,432.0</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>19456.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.85%</td>\n",
       "      <td>37888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>_features.5.1.conv1</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>147456.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10,612,224.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>608256.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>1.83%</td>\n",
       "      <td>626688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>_features.5.1.bn1</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>18,432.0</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>19456.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>37888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>_features.5.1.relu</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>1.20%</td>\n",
       "      <td>36864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>_features.5.1.conv2</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>147456.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10,612,224.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>608256.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>1.86%</td>\n",
       "      <td>626688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>_features.5.1.bn2</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>18,432.0</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>19456.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>37888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>_features.6.0.conv1</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>294912.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5,306,112.0</td>\n",
       "      <td>2,654,208.0</td>\n",
       "      <td>1198080.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>2.80%</td>\n",
       "      <td>1207296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>_features.6.0.bn1</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>11264.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>1.42%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>_features.6.0.relu</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,304.0</td>\n",
       "      <td>2,304.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>1.95%</td>\n",
       "      <td>18432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>_features.6.0.conv2</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>589824.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10,614,528.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>2368512.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>3.56%</td>\n",
       "      <td>2377728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>_features.6.0.bn2</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>11264.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>1.41%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>_features.6.0.downsample.0</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>587,520.0</td>\n",
       "      <td>294,912.0</td>\n",
       "      <td>149504.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>2.73%</td>\n",
       "      <td>158720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>_features.6.0.downsample.1</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>11264.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>1.25%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>_features.6.1.conv1</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>589824.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10,614,528.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>2368512.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>3.20%</td>\n",
       "      <td>2377728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>_features.6.1.bn1</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>11264.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>_features.6.1.relu</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,304.0</td>\n",
       "      <td>2,304.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>2.03%</td>\n",
       "      <td>18432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>_features.6.1.conv2</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>589824.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10,614,528.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>2368512.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>3.24%</td>\n",
       "      <td>2377728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>_features.6.1.bn2</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>11264.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>1.45%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>_features.7.0.conv1</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1179648.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,435,136.0</td>\n",
       "      <td>4,718,592.0</td>\n",
       "      <td>4727808.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>4.22%</td>\n",
       "      <td>4736000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>_features.7.0.bn1</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8,192.0</td>\n",
       "      <td>4,096.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1.54%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>_features.7.0.relu</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,048.0</td>\n",
       "      <td>2,048.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>2.05%</td>\n",
       "      <td>16384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>_features.7.0.conv2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>2359296.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>18,872,320.0</td>\n",
       "      <td>9,437,184.0</td>\n",
       "      <td>9445376.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>5.67%</td>\n",
       "      <td>9453568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>_features.7.0.bn2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8,192.0</td>\n",
       "      <td>4,096.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>_features.7.0.downsample.0</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,046,528.0</td>\n",
       "      <td>524,288.0</td>\n",
       "      <td>533504.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>2.97%</td>\n",
       "      <td>541696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>_features.7.0.downsample.1</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8,192.0</td>\n",
       "      <td>4,096.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1.42%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>_features.7.1.conv1</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>2359296.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>18,872,320.0</td>\n",
       "      <td>9,437,184.0</td>\n",
       "      <td>9445376.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>5.56%</td>\n",
       "      <td>9453568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>_features.7.1.bn1</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8,192.0</td>\n",
       "      <td>4,096.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1.49%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>_features.7.1.relu</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,048.0</td>\n",
       "      <td>2,048.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1.85%</td>\n",
       "      <td>16384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>_features.7.1.conv2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>2359296.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>18,872,320.0</td>\n",
       "      <td>9,437,184.0</td>\n",
       "      <td>9445376.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>5.14%</td>\n",
       "      <td>9453568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>_features.7.1.bn2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8,192.0</td>\n",
       "      <td>4,096.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>pool</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.07%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>_classifier</td>\n",
       "      <td>512</td>\n",
       "      <td>43</td>\n",
       "      <td>22059.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43,989.0</td>\n",
       "      <td>22,016.0</td>\n",
       "      <td>90284.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>2.65%</td>\n",
       "      <td>90456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11198571.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>187,888,213.0</td>\n",
       "      <td>94,029,696.0</td>\n",
       "      <td>90284.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>47118340.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      module name  input shape output shape      params memory(MB)           MAdd         Flops  MemRead(B)  MemWrite(B) duration[%]   MemR+W(B)\n",
       "0                     _features.0    3  43  43   64  22  22      9408.0       0.12    9,075,968.0   4,553,472.0     59820.0     123904.0       1.98%    183724.0\n",
       "1                     _features.1   64  22  22   64  22  22       128.0       0.12      123,904.0      61,952.0    124416.0     123904.0       1.47%    248320.0\n",
       "2                     _features.2   64  22  22   64  22  22         0.0       0.12       30,976.0      30,976.0    123904.0     123904.0       1.26%    247808.0\n",
       "3                     _features.3   64  22  22   64  11  11         0.0       0.03       61,952.0      30,976.0    123904.0      30976.0       1.96%    154880.0\n",
       "4             _features.4.0.conv1   64  11  11   64  11  11     36864.0       0.03    8,913,344.0   4,460,544.0    178432.0      30976.0       1.75%    209408.0\n",
       "5               _features.4.0.bn1   64  11  11   64  11  11       128.0       0.03       30,976.0      15,488.0     31488.0      30976.0       0.86%     62464.0\n",
       "6              _features.4.0.relu   64  11  11   64  11  11         0.0       0.03        7,744.0       7,744.0     30976.0      30976.0       1.17%     61952.0\n",
       "7             _features.4.0.conv2   64  11  11   64  11  11     36864.0       0.03    8,913,344.0   4,460,544.0    178432.0      30976.0       1.91%    209408.0\n",
       "8               _features.4.0.bn2   64  11  11   64  11  11       128.0       0.03       30,976.0      15,488.0     31488.0      30976.0       0.82%     62464.0\n",
       "9             _features.4.1.conv1   64  11  11   64  11  11     36864.0       0.03    8,913,344.0   4,460,544.0    178432.0      30976.0       1.76%    209408.0\n",
       "10              _features.4.1.bn1   64  11  11   64  11  11       128.0       0.03       30,976.0      15,488.0     31488.0      30976.0       0.82%     62464.0\n",
       "11             _features.4.1.relu   64  11  11   64  11  11         0.0       0.03        7,744.0       7,744.0     30976.0      30976.0       1.16%     61952.0\n",
       "12            _features.4.1.conv2   64  11  11   64  11  11     36864.0       0.03    8,913,344.0   4,460,544.0    178432.0      30976.0       1.78%    209408.0\n",
       "13              _features.4.1.bn2   64  11  11   64  11  11       128.0       0.03       30,976.0      15,488.0     31488.0      30976.0       0.82%     62464.0\n",
       "14            _features.5.0.conv1   64  11  11  128   6   6     73728.0       0.02    5,303,808.0   2,654,208.0    325888.0      18432.0       1.74%    344320.0\n",
       "15              _features.5.0.bn1  128   6   6  128   6   6       256.0       0.02       18,432.0       9,216.0     19456.0      18432.0       0.83%     37888.0\n",
       "16             _features.5.0.relu  128   6   6  128   6   6         0.0       0.02        4,608.0       4,608.0     18432.0      18432.0       1.16%     36864.0\n",
       "17            _features.5.0.conv2  128   6   6  128   6   6    147456.0       0.02   10,612,224.0   5,308,416.0    608256.0      18432.0       1.93%    626688.0\n",
       "18              _features.5.0.bn2  128   6   6  128   6   6       256.0       0.02       18,432.0       9,216.0     19456.0      18432.0       0.84%     37888.0\n",
       "19     _features.5.0.downsample.0   64  11  11  128   6   6      8192.0       0.02      585,216.0     294,912.0     63744.0      18432.0       1.58%     82176.0\n",
       "20     _features.5.0.downsample.1  128   6   6  128   6   6       256.0       0.02       18,432.0       9,216.0     19456.0      18432.0       0.85%     37888.0\n",
       "21            _features.5.1.conv1  128   6   6  128   6   6    147456.0       0.02   10,612,224.0   5,308,416.0    608256.0      18432.0       1.83%    626688.0\n",
       "22              _features.5.1.bn1  128   6   6  128   6   6       256.0       0.02       18,432.0       9,216.0     19456.0      18432.0       0.81%     37888.0\n",
       "23             _features.5.1.relu  128   6   6  128   6   6         0.0       0.02        4,608.0       4,608.0     18432.0      18432.0       1.20%     36864.0\n",
       "24            _features.5.1.conv2  128   6   6  128   6   6    147456.0       0.02   10,612,224.0   5,308,416.0    608256.0      18432.0       1.86%    626688.0\n",
       "25              _features.5.1.bn2  128   6   6  128   6   6       256.0       0.02       18,432.0       9,216.0     19456.0      18432.0       0.82%     37888.0\n",
       "26            _features.6.0.conv1  128   6   6  256   3   3    294912.0       0.01    5,306,112.0   2,654,208.0   1198080.0       9216.0       2.80%   1207296.0\n",
       "27              _features.6.0.bn1  256   3   3  256   3   3       512.0       0.01        9,216.0       4,608.0     11264.0       9216.0       1.42%     20480.0\n",
       "28             _features.6.0.relu  256   3   3  256   3   3         0.0       0.01        2,304.0       2,304.0      9216.0       9216.0       1.95%     18432.0\n",
       "29            _features.6.0.conv2  256   3   3  256   3   3    589824.0       0.01   10,614,528.0   5,308,416.0   2368512.0       9216.0       3.56%   2377728.0\n",
       "30              _features.6.0.bn2  256   3   3  256   3   3       512.0       0.01        9,216.0       4,608.0     11264.0       9216.0       1.41%     20480.0\n",
       "31     _features.6.0.downsample.0  128   6   6  256   3   3     32768.0       0.01      587,520.0     294,912.0    149504.0       9216.0       2.73%    158720.0\n",
       "32     _features.6.0.downsample.1  256   3   3  256   3   3       512.0       0.01        9,216.0       4,608.0     11264.0       9216.0       1.25%     20480.0\n",
       "33            _features.6.1.conv1  256   3   3  256   3   3    589824.0       0.01   10,614,528.0   5,308,416.0   2368512.0       9216.0       3.20%   2377728.0\n",
       "34              _features.6.1.bn1  256   3   3  256   3   3       512.0       0.01        9,216.0       4,608.0     11264.0       9216.0       1.30%     20480.0\n",
       "35             _features.6.1.relu  256   3   3  256   3   3         0.0       0.01        2,304.0       2,304.0      9216.0       9216.0       2.03%     18432.0\n",
       "36            _features.6.1.conv2  256   3   3  256   3   3    589824.0       0.01   10,614,528.0   5,308,416.0   2368512.0       9216.0       3.24%   2377728.0\n",
       "37              _features.6.1.bn2  256   3   3  256   3   3       512.0       0.01        9,216.0       4,608.0     11264.0       9216.0       1.45%     20480.0\n",
       "38            _features.7.0.conv1  256   3   3  512   2   2   1179648.0       0.01    9,435,136.0   4,718,592.0   4727808.0       8192.0       4.22%   4736000.0\n",
       "39              _features.7.0.bn1  512   2   2  512   2   2      1024.0       0.01        8,192.0       4,096.0     12288.0       8192.0       1.54%     20480.0\n",
       "40             _features.7.0.relu  512   2   2  512   2   2         0.0       0.01        2,048.0       2,048.0      8192.0       8192.0       2.05%     16384.0\n",
       "41            _features.7.0.conv2  512   2   2  512   2   2   2359296.0       0.01   18,872,320.0   9,437,184.0   9445376.0       8192.0       5.67%   9453568.0\n",
       "42              _features.7.0.bn2  512   2   2  512   2   2      1024.0       0.01        8,192.0       4,096.0     12288.0       8192.0       1.52%     20480.0\n",
       "43     _features.7.0.downsample.0  256   3   3  512   2   2    131072.0       0.01    1,046,528.0     524,288.0    533504.0       8192.0       2.97%    541696.0\n",
       "44     _features.7.0.downsample.1  512   2   2  512   2   2      1024.0       0.01        8,192.0       4,096.0     12288.0       8192.0       1.42%     20480.0\n",
       "45            _features.7.1.conv1  512   2   2  512   2   2   2359296.0       0.01   18,872,320.0   9,437,184.0   9445376.0       8192.0       5.56%   9453568.0\n",
       "46              _features.7.1.bn1  512   2   2  512   2   2      1024.0       0.01        8,192.0       4,096.0     12288.0       8192.0       1.49%     20480.0\n",
       "47             _features.7.1.relu  512   2   2  512   2   2         0.0       0.01        2,048.0       2,048.0      8192.0       8192.0       1.85%     16384.0\n",
       "48            _features.7.1.conv2  512   2   2  512   2   2   2359296.0       0.01   18,872,320.0   9,437,184.0   9445376.0       8192.0       5.14%   9453568.0\n",
       "49              _features.7.1.bn2  512   2   2  512   2   2      1024.0       0.01        8,192.0       4,096.0     12288.0       8192.0       1.53%     20480.0\n",
       "50                           pool  512   2   2  512   1   1         0.0       0.00            0.0           0.0         0.0          0.0       1.07%         0.0\n",
       "51                    _classifier          512           43     22059.0       0.00       43,989.0      22,016.0     90284.0        172.0       2.65%     90456.0\n",
       "total                                                        11198571.0       1.09  187,888,213.0  94,029,696.0     90284.0        172.0     100.00%  47118340.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import tensorwatch as tw\n",
    "from cnn_finetune import make_model\n",
    "\n",
    "# model = torchvision.models.resnet18(pretrained=True)\n",
    "# model = make_model('resnet50', num_classes=2, pretrained=True, input_size=(320, 320), classifier_factory=make_classifier)\n",
    "model = make_model('resnet18', num_classes=43, pretrained=True)\n",
    "tw.model_stats(model, [16, 3, 43, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAdd]: Mish is not supported!\n",
      "[Flops]: Mish is not supported!\n",
      "[Memory]: Mish is not supported!\n",
      "[MAdd]: Mish is not supported!\n",
      "[Flops]: Mish is not supported!\n",
      "[Memory]: Mish is not supported!\n",
      "[MAdd]: Mish is not supported!\n",
      "[Flops]: Mish is not supported!\n",
      "[Memory]: Mish is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveMaxPool2d is not supported!\n",
      "[Flops]: AdaptiveMaxPool2d is not supported!\n",
      "[Memory]: AdaptiveMaxPool2d is not supported!\n",
      "[MAdd]: Sigmoid is not supported!\n",
      "[Flops]: Sigmoid is not supported!\n",
      "[Memory]: Sigmoid is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Dropout2d is not supported!\n",
      "[Flops]: Dropout2d is not supported!\n",
      "[Memory]: Dropout2d is not supported!\n",
      "[MAdd]: Sigmoid is not supported!\n",
      "[Flops]: Sigmoid is not supported!\n",
      "[Memory]: Sigmoid is not supported!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>module name</th>\n",
       "      <th>input shape</th>\n",
       "      <th>output shape</th>\n",
       "      <th>params</th>\n",
       "      <th>memory(MB)</th>\n",
       "      <th>MAdd</th>\n",
       "      <th>Flops</th>\n",
       "      <th>MemRead(B)</th>\n",
       "      <th>MemWrite(B)</th>\n",
       "      <th>duration[%]</th>\n",
       "      <th>MemR+W(B)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>conv1</td>\n",
       "      <td>3  43  43</td>\n",
       "      <td>100  41  41</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9,077,400.0</td>\n",
       "      <td>4,706,800.0</td>\n",
       "      <td>33388.0</td>\n",
       "      <td>672400.0</td>\n",
       "      <td>2.49%</td>\n",
       "      <td>705788.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bn1</td>\n",
       "      <td>100  20  20</td>\n",
       "      <td>100  20  20</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>160,000.0</td>\n",
       "      <td>80,000.0</td>\n",
       "      <td>160800.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>1.44%</td>\n",
       "      <td>320800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>conv2</td>\n",
       "      <td>100  20  20</td>\n",
       "      <td>150  18  18</td>\n",
       "      <td>135150.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>87,480,000.0</td>\n",
       "      <td>43,788,600.0</td>\n",
       "      <td>700600.0</td>\n",
       "      <td>194400.0</td>\n",
       "      <td>2.90%</td>\n",
       "      <td>895000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bn2</td>\n",
       "      <td>150   9   9</td>\n",
       "      <td>150   9   9</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>48,600.0</td>\n",
       "      <td>24,300.0</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>48600.0</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>98400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>conv3</td>\n",
       "      <td>150   9   9</td>\n",
       "      <td>250   7   7</td>\n",
       "      <td>337750.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>33,075,000.0</td>\n",
       "      <td>16,549,750.0</td>\n",
       "      <td>1399600.0</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>2.16%</td>\n",
       "      <td>1448600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>bn3</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,000.0</td>\n",
       "      <td>4,500.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>conv4</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>250   2   2</td>\n",
       "      <td>250250.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2,000,000.0</td>\n",
       "      <td>1,001,000.0</td>\n",
       "      <td>1010000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.12%</td>\n",
       "      <td>1014000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>bn4</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.68%</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>conv_drop</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>fc1</td>\n",
       "      <td>250</td>\n",
       "      <td>43</td>\n",
       "      <td>10793.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21,457.0</td>\n",
       "      <td>10,750.0</td>\n",
       "      <td>44172.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>44344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>glob</td>\n",
       "      <td>250   2   2</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>ca.avg_pool</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>ca.max_pool</td>\n",
       "      <td>250   3   3</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>ca.fc1</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>15   1   1</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7,485.0</td>\n",
       "      <td>3,750.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.70%</td>\n",
       "      <td>16060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>ca.relu1</td>\n",
       "      <td>15   1   1</td>\n",
       "      <td>15   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>ca.fc2</td>\n",
       "      <td>15   1   1</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7,250.0</td>\n",
       "      <td>3,750.0</td>\n",
       "      <td>15060.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.24%</td>\n",
       "      <td>16060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>ca.sigmoid</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>250   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.64%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>sa.conv1</td>\n",
       "      <td>2   1   1</td>\n",
       "      <td>1   1   1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>195.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.20%</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>sa.sigmoid</td>\n",
       "      <td>1   1   1</td>\n",
       "      <td>1   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>localization.0</td>\n",
       "      <td>3  43  43</td>\n",
       "      <td>8  37  37</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3,219,888.0</td>\n",
       "      <td>1,620,896.0</td>\n",
       "      <td>26924.0</td>\n",
       "      <td>43808.0</td>\n",
       "      <td>19.61%</td>\n",
       "      <td>70732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>localization.1</td>\n",
       "      <td>8  37  37</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7,776.0</td>\n",
       "      <td>10,952.0</td>\n",
       "      <td>43808.0</td>\n",
       "      <td>10368.0</td>\n",
       "      <td>0.58%</td>\n",
       "      <td>54176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>localization.2</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.47%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>localization.3</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>10  14  14</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>784,000.0</td>\n",
       "      <td>393,960.0</td>\n",
       "      <td>18408.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>4.82%</td>\n",
       "      <td>26248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>localization.4</td>\n",
       "      <td>10  14  14</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,470.0</td>\n",
       "      <td>1,960.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>9800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>localization.5</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>fc_loc.0</td>\n",
       "      <td>490</td>\n",
       "      <td>32</td>\n",
       "      <td>15712.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31,328.0</td>\n",
       "      <td>15,680.0</td>\n",
       "      <td>64808.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>7.72%</td>\n",
       "      <td>64936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>fc_loc.1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>fc_loc.2</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>378.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.32%</td>\n",
       "      <td>944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>764945.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>135,932,242.0</td>\n",
       "      <td>68,217,453.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>4810412.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          module name  input shape output shape    params memory(MB)           MAdd         Flops  MemRead(B)  MemWrite(B) duration[%]  MemR+W(B)\n",
       "0               conv1    3  43  43  100  41  41    2800.0       0.64    9,077,400.0   4,706,800.0     33388.0     672400.0       2.49%   705788.0\n",
       "1                 bn1  100  20  20  100  20  20     200.0       0.15      160,000.0      80,000.0    160800.0     160000.0       1.44%   320800.0\n",
       "2               conv2  100  20  20  150  18  18  135150.0       0.19   87,480,000.0  43,788,600.0    700600.0     194400.0       2.90%   895000.0\n",
       "3                 bn2  150   9   9  150   9   9     300.0       0.05       48,600.0      24,300.0     49800.0      48600.0       0.14%    98400.0\n",
       "4               conv3  150   9   9  250   7   7  337750.0       0.05   33,075,000.0  16,549,750.0   1399600.0      49000.0       2.16%  1448600.0\n",
       "5                 bn3  250   3   3  250   3   3     500.0       0.01        9,000.0       4,500.0     11000.0       9000.0       0.13%    20000.0\n",
       "6               conv4  250   3   3  250   2   2  250250.0       0.00    2,000,000.0   1,001,000.0   1010000.0       4000.0       1.12%  1014000.0\n",
       "7                 bn4  250   1   1  250   1   1     500.0       0.00        1,000.0         500.0      3000.0       1000.0       0.68%     4000.0\n",
       "8           conv_drop  250   1   1  250   1   1       0.0       0.00            0.0           0.0         0.0          0.0       0.03%        0.0\n",
       "9                 fc1          250           43   10793.0       0.00       21,457.0      10,750.0     44172.0        172.0       0.13%    44344.0\n",
       "10               glob  250   2   2  250   1   1       0.0       0.00            0.0           0.0         0.0          0.0       0.13%        0.0\n",
       "11        ca.avg_pool  250   3   3  250   1   1       0.0       0.00            0.0           0.0         0.0          0.0       0.69%        0.0\n",
       "12        ca.max_pool  250   3   3  250   1   1       0.0       0.00            0.0           0.0         0.0          0.0       0.18%        0.0\n",
       "13             ca.fc1  250   1   1   15   1   1    3750.0       0.00        7,485.0       3,750.0     16000.0         60.0       0.70%    16060.0\n",
       "14           ca.relu1   15   1   1   15   1   1       0.0       0.00           15.0          15.0        60.0         60.0       0.05%      120.0\n",
       "15             ca.fc2   15   1   1  250   1   1    3750.0       0.00        7,250.0       3,750.0     15060.0       1000.0       0.24%    16060.0\n",
       "16         ca.sigmoid  250   1   1  250   1   1       0.0       0.00            0.0           0.0         0.0          0.0       2.64%        0.0\n",
       "17           sa.conv1    2   1   1    1   1   1      98.0       0.00          195.0          98.0       400.0          4.0      20.20%      404.0\n",
       "18         sa.sigmoid    1   1   1    1   1   1       0.0       0.00            0.0           0.0         0.0          0.0       0.06%        0.0\n",
       "19     localization.0    3  43  43    8  37  37    1184.0       0.04    3,219,888.0   1,620,896.0     26924.0      43808.0      19.61%    70732.0\n",
       "20     localization.1    8  37  37    8  18  18       0.0       0.01        7,776.0      10,952.0     43808.0      10368.0       0.58%    54176.0\n",
       "21     localization.2    8  18  18    8  18  18       0.0       0.01            0.0           0.0         0.0          0.0      30.47%        0.0\n",
       "22     localization.3    8  18  18   10  14  14    2010.0       0.01      784,000.0     393,960.0     18408.0       7840.0       4.82%    26248.0\n",
       "23     localization.4   10  14  14   10   7   7       0.0       0.00        1,470.0       1,960.0      7840.0       1960.0       0.11%     9800.0\n",
       "24     localization.5   10   7   7   10   7   7       0.0       0.00            0.0           0.0         0.0          0.0       0.15%        0.0\n",
       "25           fc_loc.0          490           32   15712.0       0.00       31,328.0      15,680.0     64808.0        128.0       7.72%    64936.0\n",
       "26           fc_loc.1           32           32       0.0       0.00            0.0           0.0         0.0          0.0       0.09%        0.0\n",
       "27           fc_loc.2           32            6     198.0       0.00          378.0         192.0       920.0         24.0       0.32%      944.0\n",
       "total                                            764945.0       1.16  135,932,242.0  68,217,453.0       920.0         24.0     100.00%  4810412.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# ======================= spatial ==============================\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)   # 输出与输入有相同的维度\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "nclasses = 43  # GTSRB as 43 classes\n",
    "\n",
    "def mish_fun(x):\n",
    "    # tmp = np.log(1 + np.exp(x))\n",
    "    # tmp = np.tanh(tmp)\n",
    "    # tmp = tmp * x\n",
    "    return x * (torch.tanh(F.softplus(x)))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # print(\"Mish activation loaded...\")\n",
    "    def forward(self,x):\n",
    "        x = x * (torch.tanh(F.softplus(x)))\n",
    "        return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(250)\n",
    "        self.conv4 = nn.Conv2d(250, 250, kernel_size=2)\n",
    "        self.bn4 = nn.BatchNorm2d(250)\n",
    "        self.conv_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(250, nclasses)\n",
    "        self.filters = 250\n",
    "        self.glob = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        #  attention\n",
    "        self.ca = ChannelAttention(self.filters)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            # nn.ReLU(True),\n",
    "            Mish(),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            # nn.ReLU(True)\n",
    "            Mish()\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        # 子网络（全连接或卷积网络，再加上一个回归层）用来生成空间变换的参数θ，θ的形式可以多样，\n",
    "        # 如需实现2D仿射变换，θ 就是一个6维（2x3）向量的输出\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 7 * 7, 32),  # 160*32\n",
    "            # nn.ReLU(True),\n",
    "            Mish(),\n",
    "            nn.Linear(32, 3 * 2)  # 32*6\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "        # SENet\n",
    "        # self.se = nn.Sequential(\n",
    "        #     nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        #     nn.Conv2d(self.filters, self.filters // 16, kernel_size=1),\n",
    "        #     # nn.ReLU(),\n",
    "        #     Mish(),\n",
    "        #     nn.Conv2d(self.filters // 16, self.filters, kernel_size=1),\n",
    "        #     nn.Sigmoid()\n",
    "        # )\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    # 整个空间变换器包含三个部分，本地网络(Localisation Network)、网格生成器(Grid Genator)和采样器(Sampler)\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)  # torch.Size([1, 10, 4, 4])\n",
    "        xs = xs.view(-1, 10 * 7 * 7)  # 361, 160\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform forward pass\n",
    "        # x = self.bn1(F.max_pool2d(F.leaky_relu(self.conv1(x)), 2))\n",
    "        x = self.bn1(F.max_pool2d(mish_fun(self.conv1(x)), 2))\n",
    "        x = self.conv_drop(x)\n",
    "        # x = self.bn2(F.max_pool2d(F.leaky_relu(self.conv2(x)), 2))\n",
    "        x = self.bn2(F.max_pool2d(mish_fun(self.conv2(x)), 2))\n",
    "        x = self.conv_drop(x)\n",
    "        # x = self.bn3(F.max_pool2d(F.leaky_relu(self.conv3(x)), 2))\n",
    "        x = self.bn3(F.max_pool2d(mish_fun(self.conv3(x)), 2))\n",
    "        x = self.conv_drop(x)\n",
    "        x1 = self.ca(x)\n",
    "        x = x * x1\n",
    "        # x = self.bn4(self.glob(F.leaky_relu(self.conv4(x))))\n",
    "        x = self.bn4(self.glob(mish_fun(self.conv4(x))))\n",
    "        x = self.conv_drop(x)\n",
    "        x1 = self.sa(x)\n",
    "        x = x * x1\n",
    "        x = x.view(-1, 250)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "import tensorwatch as tw\n",
    "\n",
    "tw.model_stats(model, [16, 3, 43, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = \n",
    "        self.fc1 = nn.Linear(2250, 350)\n",
    "        self.fc2 = nn.Linear(350, nclasses)\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        # 子网络（全连接或卷积网络，再加上一个回归层）用来生成空间变换的参数θ，θ的形式可以多样，\n",
    "        # 如需实现2D仿射变换，θ 就是一个6维（2x3）向量的输出\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 7 * 7, 32),                # 160*32\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)                      # 32*6\n",
    "            )\n",
    "   \n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    # 整个空间变换器包含三个部分，本地网络(Localisation Network)、网格生成器(Grid Genator)和采样器(Sampler)\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)         # torch.Size([1, 10, 4, 4])\n",
    "        xs = xs.view(-1, 10 * 7 * 7)               # 361, 160\n",
    "        print(xs.size())\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        print(theta.size())\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform forward pass\n",
    "        x = self.bn1(F.max_pool2d(F.leaky_relu(self.conv1(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn2(F.max_pool2d(F.leaky_relu(self.conv2(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn3(F.max_pool2d(F.leaky_relu(self.conv3(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = x.view(-1, 2250)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 490])\n",
      "torch.Size([1, 2, 3])\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>module name</th>\n",
       "      <th>input shape</th>\n",
       "      <th>output shape</th>\n",
       "      <th>params</th>\n",
       "      <th>memory(MB)</th>\n",
       "      <th>MAdd</th>\n",
       "      <th>Flops</th>\n",
       "      <th>MemRead(B)</th>\n",
       "      <th>MemWrite(B)</th>\n",
       "      <th>duration[%]</th>\n",
       "      <th>MemR+W(B)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>conv1</td>\n",
       "      <td>3  43  43</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>9408.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>9,075,968.0</td>\n",
       "      <td>4,553,472.0</td>\n",
       "      <td>59820.0</td>\n",
       "      <td>123904.0</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>183724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bn1</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>123,904.0</td>\n",
       "      <td>61,952.0</td>\n",
       "      <td>124416.0</td>\n",
       "      <td>123904.0</td>\n",
       "      <td>1.20%</td>\n",
       "      <td>248320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>123904.0</td>\n",
       "      <td>123904.0</td>\n",
       "      <td>0.71%</td>\n",
       "      <td>247808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>maxpool</td>\n",
       "      <td>64  22  22</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>61,952.0</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>123904.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.84%</td>\n",
       "      <td>154880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>layer1.0.conv1</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8,913,344.0</td>\n",
       "      <td>4,460,544.0</td>\n",
       "      <td>178432.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>2.99%</td>\n",
       "      <td>209408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>layer1.0.bn1</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>15,488.0</td>\n",
       "      <td>31488.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>0.94%</td>\n",
       "      <td>62464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>layer1.0.relu</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7,744.0</td>\n",
       "      <td>7,744.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>0.67%</td>\n",
       "      <td>61952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>layer1.0.conv2</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8,913,344.0</td>\n",
       "      <td>4,460,544.0</td>\n",
       "      <td>178432.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.51%</td>\n",
       "      <td>209408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>layer1.0.bn2</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>15,488.0</td>\n",
       "      <td>31488.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>0.96%</td>\n",
       "      <td>62464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>layer1.1.conv1</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8,913,344.0</td>\n",
       "      <td>4,460,544.0</td>\n",
       "      <td>178432.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.48%</td>\n",
       "      <td>209408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>layer1.1.bn1</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>15,488.0</td>\n",
       "      <td>31488.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>0.92%</td>\n",
       "      <td>62464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>layer1.1.relu</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7,744.0</td>\n",
       "      <td>7,744.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>0.66%</td>\n",
       "      <td>61952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>layer1.1.conv2</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8,913,344.0</td>\n",
       "      <td>4,460,544.0</td>\n",
       "      <td>178432.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>1.47%</td>\n",
       "      <td>209408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>layer1.1.bn2</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>30,976.0</td>\n",
       "      <td>15,488.0</td>\n",
       "      <td>31488.0</td>\n",
       "      <td>30976.0</td>\n",
       "      <td>0.97%</td>\n",
       "      <td>62464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>layer2.0.conv1</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>73728.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5,303,808.0</td>\n",
       "      <td>2,654,208.0</td>\n",
       "      <td>325888.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>2.90%</td>\n",
       "      <td>344320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>layer2.0.bn1</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>18,432.0</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>19456.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.99%</td>\n",
       "      <td>37888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>layer2.0.relu</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.65%</td>\n",
       "      <td>36864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>layer2.0.conv2</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>147456.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10,612,224.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>608256.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>3.01%</td>\n",
       "      <td>626688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>layer2.0.bn2</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>18,432.0</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>19456.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.93%</td>\n",
       "      <td>37888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>layer2.0.downsample.0</td>\n",
       "      <td>64  11  11</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>585,216.0</td>\n",
       "      <td>294,912.0</td>\n",
       "      <td>63744.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>2.15%</td>\n",
       "      <td>82176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>layer2.0.downsample.1</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>18,432.0</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>19456.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.91%</td>\n",
       "      <td>37888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>layer2.1.conv1</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>147456.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10,612,224.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>608256.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>1.60%</td>\n",
       "      <td>626688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>layer2.1.bn1</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>18,432.0</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>19456.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.91%</td>\n",
       "      <td>37888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>layer2.1.relu</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.65%</td>\n",
       "      <td>36864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>layer2.1.conv2</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>147456.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10,612,224.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>608256.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>626688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>layer2.1.bn2</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>18,432.0</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>19456.0</td>\n",
       "      <td>18432.0</td>\n",
       "      <td>0.91%</td>\n",
       "      <td>37888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>layer3.0.conv1</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>294912.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5,306,112.0</td>\n",
       "      <td>2,654,208.0</td>\n",
       "      <td>1198080.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>3.19%</td>\n",
       "      <td>1207296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>layer3.0.bn1</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>11264.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>0.94%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>layer3.0.relu</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,304.0</td>\n",
       "      <td>2,304.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>0.67%</td>\n",
       "      <td>18432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>layer3.0.conv2</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>589824.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10,614,528.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>2368512.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>3.55%</td>\n",
       "      <td>2377728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>layer3.0.bn2</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>11264.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>0.94%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>layer3.0.downsample.0</td>\n",
       "      <td>128   6   6</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>587,520.0</td>\n",
       "      <td>294,912.0</td>\n",
       "      <td>149504.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>2.55%</td>\n",
       "      <td>158720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>layer3.0.downsample.1</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>11264.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>0.92%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>layer3.1.conv1</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>589824.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10,614,528.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>2368512.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>2.11%</td>\n",
       "      <td>2377728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>layer3.1.bn1</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>11264.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>1.39%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>layer3.1.relu</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,304.0</td>\n",
       "      <td>2,304.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>0.97%</td>\n",
       "      <td>18432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>layer3.1.conv2</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>589824.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10,614,528.0</td>\n",
       "      <td>5,308,416.0</td>\n",
       "      <td>2368512.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>2.45%</td>\n",
       "      <td>2377728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>layer3.1.bn2</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,216.0</td>\n",
       "      <td>4,608.0</td>\n",
       "      <td>11264.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>1.38%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1179648.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9,435,136.0</td>\n",
       "      <td>4,718,592.0</td>\n",
       "      <td>4727808.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>4.90%</td>\n",
       "      <td>4736000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>layer4.0.bn1</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8,192.0</td>\n",
       "      <td>4,096.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1.47%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>layer4.0.relu</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,048.0</td>\n",
       "      <td>2,048.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.70%</td>\n",
       "      <td>16384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>2359296.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>18,872,320.0</td>\n",
       "      <td>9,437,184.0</td>\n",
       "      <td>9445376.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>6.88%</td>\n",
       "      <td>9453568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>layer4.0.bn2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8,192.0</td>\n",
       "      <td>4,096.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1.06%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>layer4.0.downsample.0</td>\n",
       "      <td>256   3   3</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,046,528.0</td>\n",
       "      <td>524,288.0</td>\n",
       "      <td>533504.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>2.54%</td>\n",
       "      <td>541696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>layer4.0.downsample.1</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8,192.0</td>\n",
       "      <td>4,096.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.93%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>layer4.1.conv1</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>2359296.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>18,872,320.0</td>\n",
       "      <td>9,437,184.0</td>\n",
       "      <td>9445376.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>5.17%</td>\n",
       "      <td>9453568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>layer4.1.bn1</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8,192.0</td>\n",
       "      <td>4,096.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1.06%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>layer4.1.relu</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,048.0</td>\n",
       "      <td>2,048.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>16384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>layer4.1.conv2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>2359296.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>18,872,320.0</td>\n",
       "      <td>9,437,184.0</td>\n",
       "      <td>9445376.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>4.78%</td>\n",
       "      <td>9453568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>layer4.1.bn2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8,192.0</td>\n",
       "      <td>4,096.0</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>1.03%</td>\n",
       "      <td>20480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>avgpool</td>\n",
       "      <td>512   2   2</td>\n",
       "      <td>512   1   1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.08%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>fc</td>\n",
       "      <td>512</td>\n",
       "      <td>1000</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,023,000.0</td>\n",
       "      <td>512,000.0</td>\n",
       "      <td>2054048.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.28%</td>\n",
       "      <td>2058048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>localization.0</td>\n",
       "      <td>3  43  43</td>\n",
       "      <td>8  37  37</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3,219,888.0</td>\n",
       "      <td>1,620,896.0</td>\n",
       "      <td>26924.0</td>\n",
       "      <td>43808.0</td>\n",
       "      <td>1.68%</td>\n",
       "      <td>70732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>localization.1</td>\n",
       "      <td>8  37  37</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7,776.0</td>\n",
       "      <td>10,952.0</td>\n",
       "      <td>43808.0</td>\n",
       "      <td>10368.0</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>54176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>localization.2</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,592.0</td>\n",
       "      <td>2,592.0</td>\n",
       "      <td>10368.0</td>\n",
       "      <td>10368.0</td>\n",
       "      <td>0.68%</td>\n",
       "      <td>20736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>localization.3</td>\n",
       "      <td>8  18  18</td>\n",
       "      <td>10  14  14</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>784,000.0</td>\n",
       "      <td>393,960.0</td>\n",
       "      <td>18408.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>1.19%</td>\n",
       "      <td>26248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>localization.4</td>\n",
       "      <td>10  14  14</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,470.0</td>\n",
       "      <td>1,960.0</td>\n",
       "      <td>7840.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>0.93%</td>\n",
       "      <td>9800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>localization.5</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>10   7   7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>490.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>0.67%</td>\n",
       "      <td>3920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>fc_loc.0</td>\n",
       "      <td>490</td>\n",
       "      <td>32</td>\n",
       "      <td>15712.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31,328.0</td>\n",
       "      <td>15,680.0</td>\n",
       "      <td>64808.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.84%</td>\n",
       "      <td>64936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>fc_loc.1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.50%</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>fc_loc.2</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>378.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.65%</td>\n",
       "      <td>944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11708616.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>192,915,178.0</td>\n",
       "      <td>96,566,434.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>49337680.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 module name  input shape output shape      params memory(MB)           MAdd         Flops  MemRead(B)  MemWrite(B) duration[%]   MemR+W(B)\n",
       "0                      conv1    3  43  43   64  22  22      9408.0       0.12    9,075,968.0   4,553,472.0     59820.0     123904.0       2.62%    183724.0\n",
       "1                        bn1   64  22  22   64  22  22       128.0       0.12      123,904.0      61,952.0    124416.0     123904.0       1.20%    248320.0\n",
       "2                       relu   64  22  22   64  22  22         0.0       0.12       30,976.0      30,976.0    123904.0     123904.0       0.71%    247808.0\n",
       "3                    maxpool   64  22  22   64  11  11         0.0       0.03       61,952.0      30,976.0    123904.0      30976.0       1.84%    154880.0\n",
       "4             layer1.0.conv1   64  11  11   64  11  11     36864.0       0.03    8,913,344.0   4,460,544.0    178432.0      30976.0       2.99%    209408.0\n",
       "5               layer1.0.bn1   64  11  11   64  11  11       128.0       0.03       30,976.0      15,488.0     31488.0      30976.0       0.94%     62464.0\n",
       "6              layer1.0.relu   64  11  11   64  11  11         0.0       0.03        7,744.0       7,744.0     30976.0      30976.0       0.67%     61952.0\n",
       "7             layer1.0.conv2   64  11  11   64  11  11     36864.0       0.03    8,913,344.0   4,460,544.0    178432.0      30976.0       1.51%    209408.0\n",
       "8               layer1.0.bn2   64  11  11   64  11  11       128.0       0.03       30,976.0      15,488.0     31488.0      30976.0       0.96%     62464.0\n",
       "9             layer1.1.conv1   64  11  11   64  11  11     36864.0       0.03    8,913,344.0   4,460,544.0    178432.0      30976.0       1.48%    209408.0\n",
       "10              layer1.1.bn1   64  11  11   64  11  11       128.0       0.03       30,976.0      15,488.0     31488.0      30976.0       0.92%     62464.0\n",
       "11             layer1.1.relu   64  11  11   64  11  11         0.0       0.03        7,744.0       7,744.0     30976.0      30976.0       0.66%     61952.0\n",
       "12            layer1.1.conv2   64  11  11   64  11  11     36864.0       0.03    8,913,344.0   4,460,544.0    178432.0      30976.0       1.47%    209408.0\n",
       "13              layer1.1.bn2   64  11  11   64  11  11       128.0       0.03       30,976.0      15,488.0     31488.0      30976.0       0.97%     62464.0\n",
       "14            layer2.0.conv1   64  11  11  128   6   6     73728.0       0.02    5,303,808.0   2,654,208.0    325888.0      18432.0       2.90%    344320.0\n",
       "15              layer2.0.bn1  128   6   6  128   6   6       256.0       0.02       18,432.0       9,216.0     19456.0      18432.0       0.99%     37888.0\n",
       "16             layer2.0.relu  128   6   6  128   6   6         0.0       0.02        4,608.0       4,608.0     18432.0      18432.0       0.65%     36864.0\n",
       "17            layer2.0.conv2  128   6   6  128   6   6    147456.0       0.02   10,612,224.0   5,308,416.0    608256.0      18432.0       3.01%    626688.0\n",
       "18              layer2.0.bn2  128   6   6  128   6   6       256.0       0.02       18,432.0       9,216.0     19456.0      18432.0       0.93%     37888.0\n",
       "19     layer2.0.downsample.0   64  11  11  128   6   6      8192.0       0.02      585,216.0     294,912.0     63744.0      18432.0       2.15%     82176.0\n",
       "20     layer2.0.downsample.1  128   6   6  128   6   6       256.0       0.02       18,432.0       9,216.0     19456.0      18432.0       0.91%     37888.0\n",
       "21            layer2.1.conv1  128   6   6  128   6   6    147456.0       0.02   10,612,224.0   5,308,416.0    608256.0      18432.0       1.60%    626688.0\n",
       "22              layer2.1.bn1  128   6   6  128   6   6       256.0       0.02       18,432.0       9,216.0     19456.0      18432.0       0.91%     37888.0\n",
       "23             layer2.1.relu  128   6   6  128   6   6         0.0       0.02        4,608.0       4,608.0     18432.0      18432.0       0.65%     36864.0\n",
       "24            layer2.1.conv2  128   6   6  128   6   6    147456.0       0.02   10,612,224.0   5,308,416.0    608256.0      18432.0       1.53%    626688.0\n",
       "25              layer2.1.bn2  128   6   6  128   6   6       256.0       0.02       18,432.0       9,216.0     19456.0      18432.0       0.91%     37888.0\n",
       "26            layer3.0.conv1  128   6   6  256   3   3    294912.0       0.01    5,306,112.0   2,654,208.0   1198080.0       9216.0       3.19%   1207296.0\n",
       "27              layer3.0.bn1  256   3   3  256   3   3       512.0       0.01        9,216.0       4,608.0     11264.0       9216.0       0.94%     20480.0\n",
       "28             layer3.0.relu  256   3   3  256   3   3         0.0       0.01        2,304.0       2,304.0      9216.0       9216.0       0.67%     18432.0\n",
       "29            layer3.0.conv2  256   3   3  256   3   3    589824.0       0.01   10,614,528.0   5,308,416.0   2368512.0       9216.0       3.55%   2377728.0\n",
       "30              layer3.0.bn2  256   3   3  256   3   3       512.0       0.01        9,216.0       4,608.0     11264.0       9216.0       0.94%     20480.0\n",
       "31     layer3.0.downsample.0  128   6   6  256   3   3     32768.0       0.01      587,520.0     294,912.0    149504.0       9216.0       2.55%    158720.0\n",
       "32     layer3.0.downsample.1  256   3   3  256   3   3       512.0       0.01        9,216.0       4,608.0     11264.0       9216.0       0.92%     20480.0\n",
       "33            layer3.1.conv1  256   3   3  256   3   3    589824.0       0.01   10,614,528.0   5,308,416.0   2368512.0       9216.0       2.11%   2377728.0\n",
       "34              layer3.1.bn1  256   3   3  256   3   3       512.0       0.01        9,216.0       4,608.0     11264.0       9216.0       1.39%     20480.0\n",
       "35             layer3.1.relu  256   3   3  256   3   3         0.0       0.01        2,304.0       2,304.0      9216.0       9216.0       0.97%     18432.0\n",
       "36            layer3.1.conv2  256   3   3  256   3   3    589824.0       0.01   10,614,528.0   5,308,416.0   2368512.0       9216.0       2.45%   2377728.0\n",
       "37              layer3.1.bn2  256   3   3  256   3   3       512.0       0.01        9,216.0       4,608.0     11264.0       9216.0       1.38%     20480.0\n",
       "38            layer4.0.conv1  256   3   3  512   2   2   1179648.0       0.01    9,435,136.0   4,718,592.0   4727808.0       8192.0       4.90%   4736000.0\n",
       "39              layer4.0.bn1  512   2   2  512   2   2      1024.0       0.01        8,192.0       4,096.0     12288.0       8192.0       1.47%     20480.0\n",
       "40             layer4.0.relu  512   2   2  512   2   2         0.0       0.01        2,048.0       2,048.0      8192.0       8192.0       0.70%     16384.0\n",
       "41            layer4.0.conv2  512   2   2  512   2   2   2359296.0       0.01   18,872,320.0   9,437,184.0   9445376.0       8192.0       6.88%   9453568.0\n",
       "42              layer4.0.bn2  512   2   2  512   2   2      1024.0       0.01        8,192.0       4,096.0     12288.0       8192.0       1.06%     20480.0\n",
       "43     layer4.0.downsample.0  256   3   3  512   2   2    131072.0       0.01    1,046,528.0     524,288.0    533504.0       8192.0       2.54%    541696.0\n",
       "44     layer4.0.downsample.1  512   2   2  512   2   2      1024.0       0.01        8,192.0       4,096.0     12288.0       8192.0       0.93%     20480.0\n",
       "45            layer4.1.conv1  512   2   2  512   2   2   2359296.0       0.01   18,872,320.0   9,437,184.0   9445376.0       8192.0       5.17%   9453568.0\n",
       "46              layer4.1.bn1  512   2   2  512   2   2      1024.0       0.01        8,192.0       4,096.0     12288.0       8192.0       1.06%     20480.0\n",
       "47             layer4.1.relu  512   2   2  512   2   2         0.0       0.01        2,048.0       2,048.0      8192.0       8192.0       0.69%     16384.0\n",
       "48            layer4.1.conv2  512   2   2  512   2   2   2359296.0       0.01   18,872,320.0   9,437,184.0   9445376.0       8192.0       4.78%   9453568.0\n",
       "49              layer4.1.bn2  512   2   2  512   2   2      1024.0       0.01        8,192.0       4,096.0     12288.0       8192.0       1.03%     20480.0\n",
       "50                   avgpool  512   2   2  512   1   1         0.0       0.00            0.0           0.0         0.0          0.0       1.08%         0.0\n",
       "51                        fc          512         1000    513000.0       0.00    1,023,000.0     512,000.0   2054048.0       4000.0       1.28%   2058048.0\n",
       "52            localization.0    3  43  43    8  37  37      1184.0       0.04    3,219,888.0   1,620,896.0     26924.0      43808.0       1.68%     70732.0\n",
       "53            localization.1    8  37  37    8  18  18         0.0       0.01        7,776.0      10,952.0     43808.0      10368.0       1.18%     54176.0\n",
       "54            localization.2    8  18  18    8  18  18         0.0       0.01        2,592.0       2,592.0     10368.0      10368.0       0.68%     20736.0\n",
       "55            localization.3    8  18  18   10  14  14      2010.0       0.01      784,000.0     393,960.0     18408.0       7840.0       1.19%     26248.0\n",
       "56            localization.4   10  14  14   10   7   7         0.0       0.00        1,470.0       1,960.0      7840.0       1960.0       0.93%      9800.0\n",
       "57            localization.5   10   7   7   10   7   7         0.0       0.00          490.0         490.0      1960.0       1960.0       0.67%      3920.0\n",
       "58                  fc_loc.0          490           32     15712.0       0.00       31,328.0      15,680.0     64808.0        128.0       1.84%     64936.0\n",
       "59                  fc_loc.1           32           32         0.0       0.00           32.0          32.0       128.0        128.0       0.50%       256.0\n",
       "60                  fc_loc.2           32            6       198.0       0.00          378.0         192.0       920.0         24.0       0.65%       944.0\n",
       "total                                                   11708616.0       1.17  192,915,178.0  96,566,434.0       920.0         24.0     100.00%  49337680.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import tensorwatch as tw\n",
    "from cnn_finetune import make_model\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        # =====================================================\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        # 子网络（全连接或卷积网络，再加上一个回归层）用来生成空间变换的参数θ，θ的形式可以多样，\n",
    "        # 如需实现2D仿射变换，θ 就是一个6维（2x3）向量的输出\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 7 * 7, 32),                # 160*32\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)                      # 32*6\n",
    "            )\n",
    "   \n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "     # Spatial transformer network forward function\n",
    "    # 整个空间变换器包含三个部分，本地网络(Localisation Network)、网格生成器(Grid Genator)和采样器(Sampler)\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)         # torch.Size([1, 10, 4, 4])\n",
    "        xs = xs.view(-1, 10 * 7 * 7)               # 361, 160\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stn(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, progress=True, **kwargs):\n",
    "   \n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,**kwargs)\n",
    "\n",
    "model = resnet18(pretrained = False)\n",
    "\n",
    "tw.model_stats(model, [16, 3, 43, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
